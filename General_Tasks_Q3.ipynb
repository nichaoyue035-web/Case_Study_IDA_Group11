{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfe9628-7303-47c3-b708-31ceaf3deb1d",
   "metadata": {},
   "source": [
    "## Task 3: Parts T16 in Registered Vehicles (Adelshofen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1224138-eba9-45df-a0cd-decc7a41f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR = D:\\IDA\\Case_Study_IDA_Group11\n",
      "DATA_DIR = D:\\IDA\\Case_Study_IDA_Group11\\Data  | 存在? True\n",
      "共找到 89 个数据文件（支持后缀：csv/txt/xls/xlsx）\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1：环境 & 预览（修复版）===\n",
    "import os, re, csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ① 路径（按你的实际情况修改这两行）\n",
    "# 把这两行放进第1格（修复版）里\n",
    "BASE_DIR = Path(r\"D:\\IDA\\Case_Study_IDA_Group11\")   # 项目根目录\n",
    "DATA_DIR = BASE_DIR / \"Data\"                        # 数据目录（注意大写D）\n",
    "OUT_DIR = BASE_DIR / \"outputs\"\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"BASE_DIR = {BASE_DIR}\")\n",
    "print(f\"DATA_DIR = {DATA_DIR}  | 存在? {DATA_DIR.exists()}\")\n",
    "\n",
    "def standardize_colnames(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = (df.columns\n",
    "                    .str.strip()\n",
    "                    .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "                    .str.replace(r\"[^0-9a-zA-Z_]\", \"\", regex=True)\n",
    "                    .str.lower())\n",
    "    return df\n",
    "\n",
    "def sniff_delimiter(sample_text: str) -> str:\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(sample_text, delimiters=\",;\\t| \")\n",
    "        return dialect.delimiter\n",
    "    except Exception:\n",
    "        if \"\\t\" in sample_text: return \"\\t\"\n",
    "        if \";\" in sample_text: return \";\"\n",
    "        if \"|\" in sample_text: return \"|\"\n",
    "        return \",\"\n",
    "\n",
    "def detect_encoding(path: Path, encs=(\"utf-8\",\"utf-8-sig\",\"gbk\",\"latin1\")) -> str:\n",
    "    for enc in encs:\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=enc, errors=\"strict\") as f:\n",
    "                f.read(2048)\n",
    "            return enc\n",
    "        except Exception:\n",
    "            continue\n",
    "    return \"utf-8\"\n",
    "\n",
    "def peek_file(path: Path, n=5):\n",
    "    info = {\"file\": str(path), \"ext\": path.suffix.lower(),\n",
    "            \"rows_peeked\": 0, \"columns\": None,\n",
    "            \"delimiter\": None, \"encoding\": None, \"error\": None}\n",
    "    try:\n",
    "        if path.suffix.lower() in [\".csv\",\".txt\"]:\n",
    "            enc = detect_encoding(path)\n",
    "            with open(path, \"r\", encoding=enc, errors=\"ignore\") as f:\n",
    "                head = f.read(65536)\n",
    "                delim = sniff_delimiter(head)\n",
    "            df = pd.read_csv(path, nrows=n, encoding=enc, sep=delim, low_memory=False)\n",
    "            info.update({\"rows_peeked\": len(df), \"columns\": list(df.columns),\n",
    "                         \"delimiter\": delim, \"encoding\": enc})\n",
    "        elif path.suffix.lower() in [\".xls\",\".xlsx\"]:\n",
    "            df = pd.read_excel(path, nrows=n, engine=None)\n",
    "            info.update({\"rows_peeked\": len(df), \"columns\": list(df.columns),\n",
    "                         \"delimiter\": \"excel\", \"encoding\": \"binary\"})\n",
    "        else:\n",
    "            info[\"error\"] = \"跳过：不支持的扩展名\"\n",
    "    except Exception as e:\n",
    "        info[\"error\"] = f\"{type(e).__name__}: {e}\"\n",
    "    return info\n",
    "\n",
    "# ② 查找文件（含子文件夹）\n",
    "patterns = (\"*.csv\",\"*.txt\",\"*.xls\",\"*.xlsx\")\n",
    "all_files = []\n",
    "for pat in patterns:\n",
    "    all_files.extend(DATA_DIR.rglob(pat))\n",
    "\n",
    "print(f\"共找到 {len(all_files)} 个数据文件（支持后缀：csv/txt/xls/xlsx）\")\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    print(\"❌ 没找到任何数据文件。请检查：\\n\"\n",
    "          \"  1) BASE_DIR/DATA_DIR 路径是否正确；\\n\"\n",
    "          \"  2) 文件是否放在 data 文件夹或其子文件夹；\\n\"\n",
    "          \"  3) 文件后缀是否为 csv/txt/xls/xlsx。\\n\"\n",
    "          \"修正路径后重新运行本单元格即可。\")\n",
    "    # 创建一个空表避免后续 KeyError\n",
    "    catalog_df = pd.DataFrame(columns=[\"file\",\"ext\",\"encoding\",\"delimiter\",\"rows_peeked\",\"columns\",\"error\"])\n",
    "else:\n",
    "    catalog = [peek_file(p, n=5) for p in all_files]\n",
    "    catalog_df = pd.DataFrame(catalog)\n",
    "    if \"file\" in catalog_df.columns:\n",
    "        catalog_df = catalog_df.sort_values(\"file\")\n",
    "\n",
    "display_cols = [\"file\",\"ext\",\"encoding\",\"delimiter\",\"rows_peeked\",\"columns\",\"error\"]\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(catalog_df[display_cols])\n",
    "except:\n",
    "    print(catalog_df[display_cols].to_string(index=False))\n",
    "\n",
    "# ③ 导出预览（有文件时才导出）\n",
    "preview_path = OUT_DIR / \"Task3_catalog_preview.json\"\n",
    "if len(catalog_df) > 0:\n",
    "    catalog_df.to_json(preview_path, force_ascii=False, orient=\"records\", indent=2)\n",
    "    print(\"预览已导出：\", preview_path)\n",
    "else:\n",
    "    print(\"当前无可导出的预览（因为未找到数据文件）。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e06413-910a-4bc1-977e-c1620ef72be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: 配置 JOIN_PLAN ===\n",
    "\n",
    "# 写法说明（很重要）：\n",
    "# - name:     给表起个内部名字（随便取，不能重复）\n",
    "# - pattern:  用通配符匹配文件名（* 支持模糊），例如 \"*Einzelteil*.*\"\n",
    "# - usecols:  \n",
    "#    · 如果写列表 [\"列1\",\"列2\"] → 只读取这些列，列名保持原样\n",
    "#    · 如果写字典 {\"旧列名\":\"新列名\"} → 只读这些列，并改成统一的新列名（推荐）\n",
    "# - keys:     用于合并的键列（必须是两边都有的列，可以多个，例如 [\"id\"] 或 [\"id\",\"date\"]）\n",
    "# - how:      合并方式，默认 \"left\"（类似 SQL 里的 LEFT JOIN）\n",
    "\n",
    "JOIN_PLAN = [\n",
    "    # 示例1：主表（Einzelteil 零件表）\n",
    "    {\n",
    "        \"name\": \"einzelteil\",\n",
    "        \"pattern\": \"*Einzelteil_T23*.*\",     # 匹配文件名里包含 \"Einzelteil_T23\" 的表\n",
    "        \"usecols\": {                        # 举例：把原始列统一成小写下划线\n",
    "            \"ID\": \"teil_id\",\n",
    "            \"Name\": \"teil_name\",\n",
    "            \"Kategorie\": \"kategorie\"\n",
    "        },\n",
    "        \"keys\": [\"teil_id\"],                 # 主键\n",
    "        \"how\": \"left\"\n",
    "    },\n",
    "\n",
    "    # 示例2：Komponente 组件表\n",
    "    {\n",
    "        \"name\": \"komponente\",\n",
    "        \"pattern\": \"*Komponente*.*\",\n",
    "        \"usecols\": {\n",
    "            \"KomponentenID\": \"teil_id\",      # 对应零件ID，改成和主表一致\n",
    "            \"Beschreibung\": \"beschreibung\"\n",
    "        },\n",
    "        \"keys\": [\"teil_id\"],\n",
    "        \"how\": \"left\"\n",
    "    },\n",
    "\n",
    "    # 示例3：Fahrzeug 车辆表\n",
    "    {\n",
    "        \"name\": \"fahrzeug\",\n",
    "        \"pattern\": \"*Fahrzeug*.*\",\n",
    "        \"usecols\": {\n",
    "            \"FahrzeugID\": \"fahrzeug_id\",\n",
    "            \"TeilID\": \"teil_id\"              # 注意这里对应零件\n",
    "        },\n",
    "        \"keys\": [\"teil_id\"],\n",
    "        \"how\": \"left\"\n",
    "    },\n",
    "\n",
    "    # 你还可以继续加 Geodaten、Logistikverzug、Zulassungen 等表\n",
    "]\n",
    "\n",
    "# 是否用自动模式（JOIN_PLAN空时才会触发）\n",
    "AUTO_MODE = (len(JOIN_PLAN) == 0)\n",
    "\n",
    "# 是否抽样（先调试用，正式跑全量时改为 None）\n",
    "SAMPLE_ROWS_PER_FILE = 100000\n",
    "print(\"✅ JOIN_PLAN 配置已加载，共定义\", len(JOIN_PLAN), \"个表。AUTO_MODE =\", AUTO_MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5e728-c6ad-447c-98c6-46558eaf092f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
