{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfe9628-7303-47c3-b708-31ceaf3deb1d",
   "metadata": {},
   "source": [
    "## Task 3: Parts T16 in Registered Vehicles (Adelshofen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1224138-eba9-45df-a0cd-decc7a41f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = D:\\IDA\\Case_Study_IDA_Group11\n",
      "SEARCH_ROOT  = D:\\IDA\\Case_Study_IDA_Group11\\Data\n",
      "✅ T16 file: D:\\IDA\\Case_Study_IDA_Group11\\Data\\Einzelteil\\Einzelteil_T16.txt\n"
     ]
    }
   ],
   "source": [
    "# === Task3 · Cell1：自动定位 + 查 T16 属于哪个 Typ（兼容有/无 Data 目录） ===\n",
    "from pathlib import Path\n",
    "import sys, re\n",
    "import pandas as pd\n",
    "\n",
    "# 0) 自动定位项目根\n",
    "def detect_project_root() -> Path:\n",
    "    here = Path.cwd()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"Einzelteil\").exists() or (p / \"Fahrzeug\").exists() or (p / \"Data\").exists():\n",
    "            return p\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        cand = Path(\"/content/drive/MyDrive/Case_Study_IDA_Group11\")\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "    return here\n",
    "\n",
    "PROJECT_ROOT = detect_project_root()\n",
    "# 有 Data 就进 Data，没有就用根目录\n",
    "SEARCH_ROOT = PROJECT_ROOT / \"Data\" if (PROJECT_ROOT / \"Data\").exists() else PROJECT_ROOT\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "print(\"SEARCH_ROOT  =\", SEARCH_ROOT)\n",
    "\n",
    "# 1) 小工具\n",
    "def find_one(root: Path, patterns):\n",
    "    cands = []\n",
    "    for pat in patterns:\n",
    "        cands += list(root.rglob(pat))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"在 {root} 下没找到：{patterns}\")\n",
    "    # 路径短优先 + 修改时间新优先\n",
    "    cands.sort(key=lambda p: (len(p.parts), -p.stat().st_mtime))\n",
    "    return cands[0]\n",
    "\n",
    "def read_any(path: Path, nrows=None, dtype=None):\n",
    "    suf = path.suffix.lower()\n",
    "    if suf in [\".xls\", \".xlsx\"]:\n",
    "        return pd.read_excel(path, nrows=nrows, dtype=dtype)\n",
    "    # csv/txt：自动分隔符 + 编码兜底\n",
    "    for enc in [None, \"utf-8-sig\", \"latin-1\", \"cp1252\"]:\n",
    "        try:\n",
    "            return pd.read_csv(path, sep=None, engine=\"python\", encoding=enc, nrows=nrows, dtype=dtype)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    return pd.read_csv(path, nrows=nrows, dtype=dtype)  # 让它抛出原生错误\n",
    "\n",
    "# 2) 找 T16 文件（csv/txt/xls/xlsx 都支持）\n",
    "t16_path = find_one(\n",
    "    SEARCH_ROOT,\n",
    "    [\"Einzelteil/Einzelteil_T16.*\", \"**/Einzelteil_T16.*\"]\n",
    ")\n",
    "print(\"✅ T16 file:\", t16_path)\n",
    "\n",
    "t16 = read_any(t16_path)\n",
    "# 识别“零件号”列（包含 'teil' 字样）\n",
    "teil_cols = [c for c in t16.columns if re.search(\"teil\", c, re.I)]\n",
    "if not teil_cols:\n",
    "    raise ValueError(f\"在 {t16_path.name} 里没找到包含 'teil' 的列；实际列名：{list(t16.columns)[:12]}\")\n",
    "teil_col = teil_cols[0]\n",
    "t16_ids = set(t16[teil_col].astype(str).unique())\n",
    "print(\"零件列:\", teil_col, \"| T16 示例:\", list(t16_ids)[:5])\n",
    "\n",
    "# 3) 在 Fahrzeug 目录里扫描 “零件-车辆对应表”\n",
    "fahrzeug_dir = (SEARCH_ROOT / \"Fahrzeug\")\n",
    "if not fahrzeug_dir.exists():\n",
    "    raise FileNotFoundError(f\"未找到目录：{fahrzeug_dir}\")\n",
    "\n",
    "maps = sorted(list(fahrzeug_dir.glob(\"Bestandteile_Fahrzeuge_*.*\")))\n",
    "if not maps:\n",
    "    raise FileNotFoundError(f\"在 {fahrzeug_dir} 下没找到 'Bestandteile_Fahrzeuge_*' 文件\")\n",
    "\n",
    "matches = []\n",
    "for f in maps:\n",
    "    try:\n",
    "        df = read_any(f, nrows=100000)  # 为了快，只读前 10 万行\n",
    "        cols = [c for c in df.columns if re.search(\"teil\", c, re.I)]\n",
    "        if not cols:\n",
    "            continue\n",
    "        col = cols[0]\n",
    "        vals = set(df[col].astype(str).unique())\n",
    "        if t16_ids & vals:\n",
    "            m = re.search(r\"Typ(\\d+)\", f.name)\n",
    "            typ = m.group(1) if m else \"?\"\n",
    "            matches.append((f.name, typ))\n",
    "            print(f\"✅ Found in: {f.name} (Typ {typ})\")\n",
    "    except Exception as e:\n",
    "        print(\"跳过\", f.name, \"→\", e)\n",
    "\n",
    "if not matches:\n",
    "    print(\"❌ 没在任何 Bestandteile_Fahrzeuge_* 里找到 T16；请确认 T16 的零件列名/值。\")\n",
    "else:\n",
    "    print(\"T16 出现于这些文件：\", matches)\n",
    "    # 你可以在下一格根据 typ 选择对应的 Fahrzeuge_* 文件继续合并分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e06413-910a-4bc1-977e-c1620ef72be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Task3 · 分批统计：Zulassungen_alle_Fahrzeuge 按块处理，避免内存卡死 ===\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- 小工具 ----------\n",
    "def detect_project_root() -> Path:\n",
    "    here = Path.cwd()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"Zulassungen\").exists() or (p / \"Data\").exists():\n",
    "            return p\n",
    "    return here\n",
    "\n",
    "def norm_id_series(s: pd.Series) -> pd.Series:\n",
    "    # 统一 ID：去空格、去掉尾部“.0”\n",
    "    return s.astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "\n",
    "def open_zulassungen_path(search_root: Path) -> Path:\n",
    "    p = next((x for x in search_root.rglob(\"**/Zulassungen_alle_Fahrzeuge.*\")), None)\n",
    "    if p is None:\n",
    "        p = next((x for x in search_root.rglob(\"**/Zulassungen*Fahrzeuge.*\")), None)\n",
    "    if p is None:\n",
    "        raise FileNotFoundError(\"未找到 Zulassungen_alle_Fahrzeuge.*\")\n",
    "    if p.suffix.lower() != \".csv\":\n",
    "        raise ValueError(f\"找到的是 {p.name}（{p.suffix}）。分批读取建议先把它另存为 CSV 再跑。\")\n",
    "    return p\n",
    "\n",
    "# ---------- 前置检查 ----------\n",
    "if \"veh_ids\" not in globals() or len(veh_ids) == 0:\n",
    "    raise RuntimeError(\"veh_ids 未定义或为空。请先用前面的 Cell 计算出使用 T16 的车辆 ID 集合（veh_ids）。\")\n",
    "\n",
    "PROJECT_ROOT = detect_project_root()\n",
    "SEARCH_ROOT  = PROJECT_ROOT / \"Data\" if (PROJECT_ROOT / \"Data\").exists() else PROJECT_ROOT\n",
    "zul_path = open_zulassungen_path(SEARCH_ROOT)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"Zulassungen CSV:\", zul_path)\n",
    "print(\"veh_ids size:\", len(veh_ids))\n",
    "\n",
    "# 规范化一下 veh_ids\n",
    "veh_ids_n = { re.sub(r\"\\.0$\", \"\", str(x).strip()) for x in veh_ids }\n",
    "\n",
    "# ---------- 分批统计 ----------\n",
    "chunksize = 500_000  # 每块 50 万行，可按机器内存情况调大/调小\n",
    "vehicles_all = set()       # 使用 T16 的唯一车辆（全区域）\n",
    "vehicles_adel = set()      # Adelshofen 的唯一车辆\n",
    "rows_adel = 0              # Adelshofen 的记录行数\n",
    "city_veh = defaultdict(set)  # 城市 -> 唯一车辆集合（用于 Top10）\n",
    "\n",
    "reader = pd.read_csv(\n",
    "    zul_path,\n",
    "    sep=None, engine=\"python\", encoding=\"utf-8\",\n",
    "    dtype={\"IDNummer\": \"string\"},\n",
    "    chunksize=chunksize,\n",
    ")\n",
    "\n",
    "for i, chunk in enumerate(reader, start=1):\n",
    "    # 规范字段\n",
    "    if \"IDNummer\" not in chunk.columns or \"Gemeinden\" not in chunk.columns:\n",
    "        # 列名安全处理\n",
    "        chunk.columns = [str(c).strip() for c in chunk.columns]\n",
    "    # 统一格式\n",
    "    chunk[\"IDNummer_n\"] = norm_id_series(chunk[\"IDNummer\"])\n",
    "    chunk[\"Gemeinden_u\"] = chunk[\"Gemeinden\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "    # 先按 veh_ids 过滤\n",
    "    part = chunk[chunk[\"IDNummer_n\"].isin(veh_ids_n)].copy()\n",
    "    if not part.empty:\n",
    "        # 全区域唯一车辆\n",
    "        vehicles_all.update(part[\"IDNummer_n\"].unique())\n",
    "\n",
    "        # Adelshofen\n",
    "        mask_adel = part[\"Gemeinden_u\"] == \"ADELSHOFEN\"\n",
    "        rows_adel += int(mask_adel.sum())\n",
    "        if mask_adel.any():\n",
    "            vehicles_adel.update(part.loc[mask_adel, \"IDNummer_n\"].unique())\n",
    "\n",
    "        # 各城市唯一车辆（分块去重后再累计，避免膨胀）\n",
    "        dedup = part.drop_duplicates(subset=[\"Gemeinden_u\", \"IDNummer_n\"])\n",
    "        for city, ids in dedup.groupby(\"Gemeinden_u\")[\"IDNummer_n\"]:\n",
    "            city_veh[city].update(ids.values)\n",
    "\n",
    "    print(f\"Processed chunk {i:>2d}: rows={len(chunk):,} | matched={len(part):,} | \"\n",
    "          f\"vehicles_all={len(vehicles_all):,} | adel_rows={rows_adel:,}\")\n",
    "\n",
    "# ---------- 汇总结果 ----------\n",
    "vehicles_all_n = len(vehicles_all)\n",
    "vehicles_adel_n = len(vehicles_adel)\n",
    "\n",
    "# Top10 城市（按唯一车辆数排）\n",
    "top10 = sorted(((city, len(ids)) for city, ids in city_veh.items()),\n",
    "               key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"\\n===== FINAL RESULTS =====\")\n",
    "print(\"Vehicles using T16 (all regions, unique):\", vehicles_all_n)\n",
    "print(\"Vehicles registered in Adelshofen with T16 (unique):\", vehicles_adel_n)\n",
    "print(\"Number of rows in Adelshofen:\", rows_adel)\n",
    "\n",
    "print(\"\\nTop 10 Gemeinden by vehicles with T16 (unique vehicles):\")\n",
    "for city, cnt in top10:\n",
    "    print(f\"{city:20s}  {cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7234026-47ea-4394-9b36-2000a47f4e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
